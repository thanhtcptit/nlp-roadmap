# NLP learning roadmap for beginner
1. Overview
    1. [What is NLP](https://en.wikipedia.org/wiki/Natural_language_processing)
    2. Some major tasks of NLP
        * [Part-of-speech Tagging](https://en.wikipedia.org/wiki/Part-of-speech_tagging) & [Parsing](https://en.wikipedia.org/wiki/Parsing)
        * [Named Entity Recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)
        * [Coreference Resolution](https://en.wikipedia.org/wiki/Coreference)
        * [Sentiment Analysis](https://en.wikipedia.org/wiki/Sentiment_analysis)
        * [Machine Translation](https://en.wikipedia.org/wiki/Machine_translation)
        * [Question Answering](https://en.wikipedia.org/wiki/Question_answering)
        * [Reading Comprehension](https://en.wikipedia.org/wiki/Reading_comprehension)
        * [Summarization](https://en.wikipedia.org/wiki/Automatic_summarization)
        * [Language Modelling](https://en.wikipedia.org/wiki/Language_model)
        * [Speech Recognition](https://en.wikipedia.org/wiki/Speech_recognition)
2. Text Classification
    1. [Vector Representation of Text & Bag-of-words Model](https://sheffieldnlp.github.io/com4513-6513/assets/slides/lec1_intro_vector.pdf)
    2. [Naive Bayes](https://medium.com/analytics-vidhya/naive-bayes-classifier-for-text-classification-556fabaf252b)
    3. [Logistic Regression](https://medium.com/analytics-vidhya/applying-text-classification-using-logistic-regression-a-comparison-between-bow-and-tf-idf-1f1ed1b83640)
    4. [Feedforward Neural Network](https://sheffieldnlp.github.io/com4513-6513/assets/slides/lec6_fnn.pdf)
    5. [NLP Text Preprocessing Technique](https://towardsdatascience.com/nlp-text-preprocessing-a-practical-guide-and-template-d80874676e79)
3. Word Embeddings
    1. [Word2Vec Overview](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa)
    2. [Glove](https://nlp.stanford.edu/projects/glove/)
    3. [ELMo](https://allennlp.org/elmo)
    4. [Doc2vec](https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e)
    5. [Bias in Word Embeddings](https://medium.com/@dhartidhami/bias-in-word-embeddings-4ce8e4261c7)
4. Named Entity Recogniton
    1. [Recurrent Neural Network](https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9)
    2. [GRU & LSTM](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)
    3. [Bidirectional LSTM + CNN](https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00104)
    4. [Recurrent Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks#architecture)
5. Part-of-speech Tagging
    1. [Hidden Markov Model](https://medium.com/hackernoon/building-a-bigram-hidden-markov-model-for-part-of-speech-tagging-1b784a87ab2c)
    2. [CharCNN](https://www.aclweb.org/anthology/L18-1446.pdf)
6. Machine Translation
    1. [Seq2seq Encoder-Decoder Network](https://github.com/tensorflow/nmt)
    2. [Transformer](http://jalammar.github.io/illustrated-transformer/)
    3. [Back-Translation](https://arxiv.org/pdf/1808.09381.pdf)
7. Language Modelling
    1. [N-gram Language Model](https://web.stanford.edu/~jurafsky/slp3/3.pdf)
    2. [Character Aware Neural Language Model](https://hyunyoung2.github.io/2018/11/30/Character-Aware_Neural_Language_Models/)
    3. [BERT](http://jalammar.github.io/illustrated-bert/)
    4. [XLNet](https://mlexplained.com/2019/06/30/paper-dissected-xlnet-generalized-autoregressive-pretraining-for-language-understanding-explained/)
8. Supplementary Topics
    1. Text Similarity
        * [Siamese Network](https://www.researchgate.net/publication/304834009_Learning_Text_Similarity_with_Siamese_Recurrent_Networks)
    2. Topic Modelling
        * [Non Negative Matrix Factorization](https://blog.acolyer.org/2019/02/18/the-why-and-how-of-nonnegative-matrix-factorization/)
        * [Latent Dirichlet Allocation](https://medium.com/@jonathan_hui/machine-learning-latent-dirichlet-allocation-lda-1d9d148f13a4)
    3. Text Summarization
        * [BERTSum](https://arxiv.org/pdf/1908.08345.pdf)
    4. Coreference Resolution
        * [Neural Coreference Model](https://towardsdatascience.com/deep-into-end-to-end-neural-coreference-model-58c317cfdb83)

# Courses, books & ref
* https://sheffieldnlp.github.io/com4513-6513/pages/schedule.html
* http://cs224n.stanford.edu/
* https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf
* https://web.stanford.edu/~jurafsky/slp3/
* https://paperswithcode.com/area/natural-language-processing
* https://github.com/keon/awesome-nlp